{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d7247d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "import nltk.tokenize as token\n",
    "from nltk.tokenize import WhitespaceTokenizer, WordPunctTokenizer, TreebankWordTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "import time\n",
    "import string\n",
    "\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import numpy as np\n",
    "from string import punctuation\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d692ec",
   "metadata": {},
   "source": [
    "## Preprocessing definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c5a1a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_lower(text):\n",
    "    # return the reviews after convering then to lowercase\n",
    "    # Words with different cases are intercepted differently such as 'The' and 'the'. \n",
    "    # Hence all words should be converted into same case, preferably lower case.\n",
    "    l = []\n",
    "    for t in text:\n",
    "        l.append(t.lower())\n",
    "    return remove_punctuation(l)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    # return the reviews after removing punctuations\n",
    "    # Refer: https://www3.ntu.edu.sg/home/ehchua/programming/howto/Regexe.html\n",
    "    l = []\n",
    "    # \\w : word character\n",
    "    # \\W : non-word character\n",
    "    # \\d : digits\n",
    "    # \\D : non-digits\n",
    "    \n",
    "    for t in text:\n",
    "        l.append(re.sub(r'[^\\w\\s]|^\\s\\d+\\s|\\s\\d+|\\d+|\\s\\d+$', ' ', t)) #|^\\s\\d+\\s|\\s\\d+|\\d+|\\s\\d+$\n",
    "    return remove_stopwords(l)\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    # return the reviews after removing the stopwords\n",
    "    # Stopwords are the most common words in a language. For example 'is', 'the', 'that' etc. are stopwords in English language. Stopwords shall be removed during text clean-up phase. However removing stop word can change the meaning of sentence. \n",
    "    # For instance 'I didn't love politics' will get converted to 'I love politics' after removing stopword.  \n",
    "    l = []\n",
    "    large = 0\n",
    "    for t in text:\n",
    "        word_tokens = token.word_tokenize(t)\n",
    "        filtered_sentence = [w for w in word_tokens if not w in stop_words]\n",
    "        l.append(filtered_sentence)\n",
    "    return l\n",
    "\n",
    "def remove_URLs(text):\n",
    "    text  = re.sub(r\"https?://\\S+|www\\.\\S+\", \"\", text )\n",
    "    return remove_digits(text)\n",
    "\n",
    "def remove_digits(text):\n",
    "    text= re.sub(r'[0-9]','',text)\n",
    "    return remove_spaces(text)\n",
    "\n",
    "def remove_spaces(text):\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2650dd1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
     ]
    }
   ],
   "source": [
    "files = gutenberg.fileids()\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c7fdd924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Where', 'is', 'thy', 'Leather', 'Apron', ',', 'and', 'thy', 'Rule', '?']\n"
     ]
    }
   ],
   "source": [
    "macbeth_sentences = gutenberg.sents('shakespeare-caesar.txt')\n",
    "print(macbeth_sentences[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "458718d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[], [], ['thy'], ['leather'], ['apron'], [], [], ['thy'], ['rule'], []]\n"
     ]
    }
   ],
   "source": [
    "clean_sentences = convert_to_lower(macbeth_sentences[11])\n",
    "# clean_sentences = remove_punctuation(clean_sentences)\n",
    "print(clean_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "13c03e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Where'], [], ['thy'], ['Leather'], ['Apron'], [','], [], ['thy'], ['Rule'], ['?']]\n"
     ]
    }
   ],
   "source": [
    "print(remove_stopwords(macbeth_sentences[11]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
